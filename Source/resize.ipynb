{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "# import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "# import skvideo.io\n",
    "from data_loader import DataClass\n",
    "# video = io.open('test.avi', 'r+b').read()\n",
    "FOLDER = \"data/resize\"\n",
    "# cv2.imshow(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = {i:0 for i in range(101)}\n",
    "train_counter = {i:0 for i in range(100)}\n",
    "val_counter = {i:0 for i in range(100)}\n",
    "arr = []\n",
    "with open(\"data/all_images1.txt\") as f:\n",
    "    for line in f:\n",
    "        label = int(line.split(\" \")[1])\n",
    "        arr.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.asarray(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[::-1].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([74, 36, 36, 36, 35, 35, 35, 34, 33, 32, 32, 27, 27, 27, 27, 26, 26,\n",
       "       26, 26, 26, 26, 26, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "       25, 25, 25, 25, 25, 24, 24, 24, 24, 24, 24, 24, 24, 23, 23, 23, 23,\n",
       "       23, 23, 23, 23, 23, 23, 23, 23, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
       "       22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 21, 21, 21, 21, 21, 21,\n",
       "       21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1091174400"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 *  296 * 3 * 160 * 240 * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_DATASET = \"data/\"\n",
    "IMAGE_DATASET = \"UCF101_images/\"\n",
    "\n",
    "dataloader = {'train' : DataClass(FOLDER_DATASET, IMAGE_DATASET, \"train1.txt\"),\n",
    "              'validation' : DataClass(FOLDER_DATASET, IMAGE_DATASET, \"val1.txt\")}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, label = dataloader['train'].getbatch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.from_numpy(input).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNGRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNGRU, self).__init__()\n",
    "        self.input_dim = 1000\n",
    "        self.hidden_layers = 101\n",
    "        self.rnn_layers = 2\n",
    "#         self.classes = 101\n",
    "#         self.sample_rate = 12\n",
    "        \n",
    "        self.conv = torchvision.models.resnet18(pretrained=True)\n",
    "        for param in self.conv.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_layers, self.rnn_layers)\n",
    "        self.gru = nn.GRU(self.input_dim, self.hidden_layers, self.rnn_layers, dropout=0.2)\n",
    "#         self.linear = nn.Linear(\n",
    "#             in_features=self.hidden_layers, out_features=self.classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n, t,c, w, h = x.size(0), x.size(1), x.size(2), x.size(3), x.size(4)\n",
    "        x = x.view(t*n,c,w,h)\n",
    "        conv_output = self.conv(x) #convolve allframes       \n",
    "        conv_output = conv_output.view(n,t,-1).transpose(1,0)\n",
    "#         conv_output = self.conv(x).view(x.size(0),x.size(1),-1).transpose(1,0)\n",
    "        out, _ = self.gru(conv_output) # pass convolution to gru\n",
    "        lstm_output = out[-1, :, :].data\n",
    "#         print(lstm_output.size())\n",
    "#         output = self.linear(lstm_output) #linear layer \n",
    "        return lstm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to C:\\Users\\Ashkan/.cache\\torch\\checkpoints\\resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2dc8001e9ef41bda5a02b5df4fba729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=46827520), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "use_gpu = False\n",
    "model_ft = CNNGRU()\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "# print(model_ft)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Remove all parameters not to be optimized\n",
    "ignored_params = list(map(id, model_ft.conv.parameters()))\n",
    "base_params = filter(lambda p: id(p) not in ignored_params,\n",
    "                     model_ft.parameters())\n",
    "                     \n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD([{'params': base_params}], lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "924049"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model_ft.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403633952"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12613561 * 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = input.size()\n",
    "size[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.25 s ± 2.38 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def func():\n",
    "    input, label = dataloader['train'].getbatch(3)\n",
    "    input = Variable(torch.from_numpy(input).float())\n",
    "    model_ft(input)\n",
    "%timeit func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes about 15minutes to be completed\n",
    "with open(\"data/all_images1.txt\") as f:\n",
    "    for line in f:\n",
    "        image_folder = line.split(\" \")[0]\n",
    "        length = line.split(\" \")[1]\n",
    "        image_url =  \"data/\" + \"UCF101_images/\" + image_folder\n",
    "        image_resize_url =  \"data/\" + \"UCF101_images_r/\" + image_folder\n",
    "        \n",
    "        \n",
    "        for i in range(0, int(length)): #pad the beginning\n",
    "            image = cv2.imread(image_url + \"_\" + str(i) + \".jpg\")                \n",
    "            image = cv2.resize(image, (267,200), interpolation = cv2.INTER_AREA)\n",
    "            cv2.imwrite(image_url + \"_r_\" + str(i) + \".jpg\",image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
